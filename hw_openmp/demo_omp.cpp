// Adil Hydari
// Benchmarking with identity matrices:
//Original multiplymatrix with 1 thread: 3.95243 seconds
//Optimized multiplymatrix3 with 1 threads: 3.73333 seconds
//Transposed multiplymatrix with 1 threads: 3.77873 seconds
//Original multiplymatrix with 1 thread: 4.01997 seconds
//Optimized multiplymatrix3 with 2 threads: 1.92354 seconds
//Transposed multiplymatrix with 2 threads: 1.92314 seconds
//Original multiplymatrix with 1 thread: 3.8966 seconds
//Optimized multiplymatrix3 with 4 threads: 0.96961 seconds
//Transposed multiplymatrix with 4 threads: 0.957989 seconds
//Original multiplymatrix with 1 thread: 3.9665 seconds
//Optimized multiplymatrix3 with 8 threads: 0.499327 seconds
//Transposed multiplymatrix with 8 threads: 0.488311 seconds
//
//Benchmarking with diagonal matrices:
//Diagonal matrices multiplymatrix3 with 1 threads: 3.73382 seconds
//Diagonal matrices multiplymatrix3 with 2 threads: 1.94314 seconds
//Diagonal matrices multiplymatrix3 with 4 threads: 0.962202 seconds
//Diagonal matrices multiplymatrix3 with 8 threads: 0.492557 seconds
#include <omp.h>
#include <iostream>
#include <chrono>

// Assuming a system with 4 physical cores.
// The performance with 8 threads will indicate how well hyperthreading is utilized.
// Hyperthreading is a form of SMT, meaning that the processor will issue instructions to multiple threads on 1 core. The
// most common way in which SMT works is with interleved multithreading, meaning that every other cycle a thread on a core is
// issued an instruction. SMT only works effcently if the physical processor itself is not gated by some outside resource,
// like memory bandwidth. 

// dumb matrix multiply generated by COdium, writes to memory
void multiplymatrix(float a[], float b[], float c[], int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            c[i * n + j] = 0.0;
            #pragma omp simd
            for (int k = 0; k < n; k++) {
                c[i * n + j] += a[i * n + k] * b[k * n + j];
            }
        }
    }
}


// inner dot product uses registers, still goes in
// non-sequential direction in memory
void multiplymatrix2(float a[], float b[], float c[], int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            float dot = 0.0;
            for (int k = 0; k < n; k++) {
                dot += a[i * n + k] * b[k * n + j];
            }
            c[i * n + j] = dot;
        }
    }
}

void transpose(float* b, float* b_transposed, int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            b_transposed[j * n + i] = b[i * n + j];
        }
    }
}

void multiplymatrix_transposed(float a[], float b_transposed[], float c[], int n) {
    #pragma omp parallel for schedule(dynamic)
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            float dot = 0.0;
            #pragma omp simd
            for (int k = 0; k < n; k++) {
                dot += a[i * n + k] * b_transposed[j * n + k];
            }
            c[i * n + j] = dot;
        }
    }
}


// multithreading with OpenMP
void multiplymatrixnonsmid(float a[], float b[], float c[], int n) {

    #pragma omp parallel for
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            float dot = 0.0;
            for (int k = 0; k < n; k++) {
                dot += a[i * n + k] * b[k * n + j];
            }
            c[i * n + j] = dot;
        }
    }
}

// multithreading with OpenMP
void multiplymatrix3(float a[], float b[], float c[], int n) {

    #pragma omp parallel for schedule(dynamic)
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            float dot = 0.0;
            #pragma omp simd
            for (int k = 0; k < n; k++) {
                dot += a[i * n + k] * b[k * n + j];
            }
            c[i * n + j] = dot;
        }
    }
}

void benchmark_multiply(int n, int num_threads) {
    float* a = new float[n*n];
    float* b = new float[n*n];
    float* c = new float[n*n];

    // Create identity matrices
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            a[i * n + j] = (i == j) ? 1.0f : 0.0f;
            b[i * n + j] = (i == j) ? 1.0f : 0.0f;
        }
    }

    // Benchmark original multiplymatrix
    omp_set_num_threads(1);
    auto start = std::chrono::high_resolution_clock::now();
    multiplymatrix(a, b, c, n);
    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> duration = end - start;
    std::cout << "Original multiplymatrix with 1 thread: " << duration.count() << " seconds\n";

    // Benchmark optimized multiplymatrix3
    omp_set_num_threads(num_threads);
    start = std::chrono::high_resolution_clock::now();
    multiplymatrix3(a, b, c, n);
    end = std::chrono::high_resolution_clock::now();
    duration = end - start;
    std::cout << "Optimized multiplymatrix3 with " << num_threads << " threads: " << duration.count() << " seconds\n";

    float* b_transposed = new float[n*n];
    transpose(b, b_transposed, n);

    // Benchmark transposed multiplymatrix
    omp_set_num_threads(num_threads);
    start = std::chrono::high_resolution_clock::now();
    multiplymatrix_transposed(a, b_transposed, c, n);
    end = std::chrono::high_resolution_clock::now();
    duration = end - start;
    std::cout << "Transposed multiplymatrix with " << num_threads << " threads: " << duration.count() << " seconds\n";

    delete[] a;
    delete[] b_transposed;
    delete[] b;
    delete[] c;
}

void benchmark_diagonal_matrices(int n, int num_threads) {
    float* a = new float[n*n];
    float* b = new float[n*n];
    float* c = new float[n*n];

    // Create matrices with main diagonal 3 and others 2
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            a[i * n + j] = (i == j) ? 3.0f : 2.0f;
            b[i * n + j] = (i == j) ? 3.0f : 2.0f;
        }
    }

    // Benchmark optimized multiplymatrix3
    omp_set_num_threads(num_threads);
    auto start = std::chrono::high_resolution_clock::now();
    multiplymatrix3(a, b, c, n);
    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> duration = end - start;
    std::cout << "Diagonal matrices multiplymatrix3 with " << num_threads << " threads: " << duration.count() << " seconds\n";

    delete[] a;
    delete[] b;
    delete[] c;
}

int main() {
    int n = 1024;

    std::cout << "Benchmarking with identity matrices:\n";
    benchmark_multiply(n, 1);
    benchmark_multiply(n, 2);
    benchmark_multiply(n, 4);
    benchmark_multiply(n, 8);

    std::cout << "\nBenchmarking with diagonal matrices:\n";
    benchmark_diagonal_matrices(n, 1);
    benchmark_diagonal_matrices(n, 2);
    benchmark_diagonal_matrices(n, 4);
    benchmark_diagonal_matrices(n, 8);

    return 0;
}
